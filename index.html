<!DOCTYPE HTML>
<html lang="en">
  <head>
    
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Yingqing He</title>

    <meta name="author" content="Yingqing He">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ§¸</text></svg>">
  </head>

  <body>
    <!-- <div class="content">
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr style="padding:0px">
          <td style="padding:2.5%;width:63%;vertical-align:middle">
            <p class="name" style="text-align: center;">
              Yingqing He
            </p>
            <p>I am currently a Ph.D. student at <a href="https://hkust.edu.hk/">HKUST</a> supervised by <a href="https://cqf.io/">Prof. Qifeng Chen</a>. 
            </p>
            <p>
              I am working at AIGC-related research, including generative models, image/video generation and editing.
            </p>
            <p style="text-align:center">
              <a href="yhebm@connect.ust.hk">Email</a> &nbsp;/&nbsp;
              <a href="https://scholar.google.com/citations?user=UDiGYN8AAAAJ&hl=en">Google Scholar</a> &nbsp;/&nbsp;
              <a href="https://github.com/YingqingHe">Github</a> &nbsp;/&nbsp;
              <a href="#">LinkedIn</a>
            </p>
          </td>
          <td style="padding:2.5%;width:40%;max-width:40%">
            <a href="myassets/mypic.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="myassets/mypic.jpg" class="hoverZoomLink"></a>
          </td>
        </tr>
      </tbody></table>
    </div> -->
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Yingqing He
                </p>
                <p>
                  Hi ðŸ‘‹ðŸ˜‹. 
                  I am currently a Ph.D. student at <a href="https://hkust.edu.hk/">HKUST</a> supervised by <a href="https://cqf.io/">Prof. Qifeng Chen</a>. 
                </p>
                <p>
                  My main research focus is text-to-video generation, video diffusion models and related downstream applications.
                  I am also working at other AIGC-related researchðŸ’–.
                </p>
                <p>
                  Welcome to any types of research collaboration and discussions! 
                  Our lab is hiring engineering-oriented research assistant (RA). If you would like to apply, feel free to reach out with your CV!
                </p>
                <p style="text-align:center">
                  <a href="yhebm@connect.ust.hk">Email</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=UDiGYN8AAAAJ&hl=en">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/YingqingHe">Github</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/yingqing-he-6b2859168/">LinkedIn</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="myassets/mypic.jpg"><img style="width:75%;max-width:100%" alt="profile photo" src="myassets/mypic.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <h2>News</h2>
              <p>
                - [07/2024] 1 paper was accepted to <font style="color: #D8429E">SIGGRAPH Asia 2024</font>.<br> 
                - [07/2024] 1 paper was accepted to <font style="color: #D8429E">ECCV 2024</font>.<br> 
                - [05/2024] We released a survey paper: <a href="https://arxiv.org/abs/2405.19334">LLMs Meet Multimodal Generation and Editing: A Survey</a>.<br>
                - [03/2024] Invited talk at <a href="https://www.meituan.com/">Meituan</a> on the topic of <i>"Recent Advance of Text-to-Video Generation"</i>.<br>
                - [03/2024] 1 paper was accepted to <font style="color: #D8429E">CVPR 2024</font>.<br> 
                - [02/2024] 1 paper was accepted to <font style="color: #D8429E">TVCG 2024</font>.<br> 
                - [01/2024] 2 papers were accepted to <font style="color: #D8429E">ICLR 2024</font> (including 1 Spotlight paper).<br> 
                - [12/2023] 1 paper was accepted to <font style="color: #D8429E">AAAI 2024</font>.<br> 
                - [11/2023] Released <a href="https://arxiv.org/abs/2310.19512">VideoCrafter 1</a>.<br>
                - [08/2023] 1 paper was accepted to <font style="color: #D8429E">SIGGRAPH Asia 2023</font>.<br> 
                - [06/2023] Invited talk at <a href="https://sites.google.com/view/loveucvpr23/home">LOVEU Workshop</a> at <font style="color: #D8429E">CVPR 2023</font> on the topic of <i>"Crafting Your Videos: From Unconditional to <br>
                  &nbsp; &nbsp; &nbsp;&nbsp; &nbsp; &nbsp;&nbsp; &nbsp; &nbsp;&nbsp; &nbsp; &nbsp;&nbsp; &nbsp; &nbsp;&nbsp;&nbsp;
                  Controllable Video Diffusion Models"</i>.<br>
                - [04/2023] Released <a href="https://github.com/AILab-CVC/VideoCrafter">VideoCrafter 0.9</a>.<br>
                - [08/2021] 1 paper was accepted to <font style="color: #D8429E">ACM MM 2021</font> as an <font style="color: #D8429E">Oral</font> paper.<br> 
              </p>
            </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tbody>
      <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <h2>Publications</h2>
          <!-- <p>
            I'm interested in computer vision, generative models, image/video generation and editing.
          </p> -->
        </td>
      </tr>
      </tbody>
    </table>
    
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <!-- survey -->
      <tr>
        <td style="padding:20px;width:25%;vertical-align:middle;">
          <img src='myassets/survey.jpeg' width="100%" height="60%">
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle;">
          <a href="https://arxiv.org/abs/2405.19334">
            <span class="papertitle">LLMs Meet Multimodal Generation and Editing: A Survey</span>
          </a>
          <br>
          <strong>Yingqing He</strong>,
          <a href="https://scholar.google.com/citations?user=btgwZosAAAAJ&hl=en">Zhaoyang Liu</a>, 
          <a href="https://jingyechen.github.io/">Jingye Chen</a>, 
          <a href="https://scholar.google.com/citations?user=dghq4MQAAAAJ&hl=en">Zeyue Tian</a>, 
          <a href="https://scholar.google.com/citations?user=bLRjUzAAAAAJ&hl=en">Hongyu Liu</a>, 
          <a href="https://scholar.google.com/citations?user=Vl1X_-sAAAAJ&hl=zh-CN">Xiaowei Chi</a>, 
          <a href="#">Runtao Liu</a>, 
          <a href="https://scholar.google.com/citations?user=btgwZosAAAAJ&hl=en">Ruibin Yuan</a>, 
          <a href="https://yzxing87.github.io/">Yazhou Xing</a>, 
          <a href="https://whai362.github.io/">Wenhai Wang</a>, 
          <a href="https://jifengdai.org/">Jifeng Dai</a>, 
          <a href="https://yzhang2016.github.io" target="_blank">Yong Zhang</a>,
          <a href="http://wei-xue.com/">Wei Xue</a>, 
          <a href="#">Qifeng Liu</a>, 
          <a href="https://scholar.google.com/citations?user=-0q6cIYAAAAJ&hl=en">Yike Guo</a>, 
          <a href="https://cqf.io/">Qifeng Chen</a>
          <br>
          <em>arXiv</em>, 2024
          <br>
          <a href="https://arxiv.org/abs/2405.19334">arXiv</a> / 
          <a href="https://github.com/YingqingHe/Awesome-LLMs-meet-Multimodal-Generation">Github</a>
          <p>This survey includes works of <em>image, video, 3D, and audio</em> generation and editing. 
            We emphasize the roles of LLMs on the generation and editing of these modalities.
            We also includes works of multimodal agents and generative AI safety.

          </p>
          <p>
          </p>
        </td>
      </tr>

      
      <!-- follow-your-click -->
      <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <img src='myassets/click.jpg' width="100%">
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://follow-your-click.github.io/">
            <span class="papertitle">Follow-Your-Click: Open-domain Regional Image Animation via Short Prompts  </span>
          </a>
          <br>
          <a href="https://mayuelala.github.io/" >Yue Ma</a><sup>*</sup>,
          <strong>Yingqing He</strong><sup>*</sup>,
          <a href="#">Hongfa Wang</a>, 
          <a href="#">Andong Wang</a>, 
          <a href="https://chenyangqiqi.github.io/">Chenyang Qi</a>, 
          <a href="#">Chengfei Cai</a>, 
          <a href="">Xiu Li</a>, 
          <a href="">Zhifeng Li</a>, 
          <a href="https://scholar.google.com.hk/citations?user=9akH-n8AAAAJ&hl=en">Heung-Yeung Shum</a>, 
          <a href="https://scholar.google.com/citations?user=AjxoEpIAAAAJ&hl=zh-CN">Wei Liu</a>, 
          <a href="https://cqf.io/">Qifeng Chen</a>
          <br>
          <em>arXiv</em>, 2024
          <br>
          <a href="https://follow-your-click.github.io/">Project page</a> / 
          <a href="https://arxiv.org/abs/2403.08268">arXiv</a> / 
          <a href="https://github.com/mayuelala/FollowYourClick">Github</a>
          <p></p>
          <p>
          </p>
        </td>
      </tr>



      <!-- follow-your-emoji -->
      <tr>
        <td style="padding:20px;width:25%;vertical-align:middle;">
          <video  width=100% height=100% muted autoplay loop>
            <source src="myassets/fye.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle;">
          <a href="https://follow-your-click.github.io/">
            <span class="papertitle">Follow-Your-Emoji: Fine-Controllable and Expressive Freestyle Portrait Animation</span>
          </a>
          <br>
          <a href="https://mayuelala.github.io/">Yue Ma</a>,
          <a href="#">Hongyu Liu</a>, 
          <a href="#">Hongfa Wang</a>, 
          <a href="#">Heng Pan</a>, 
          <strong>Yingqing He</strong>,
          <a href="#">Heng Pan</a>, 
          <a href="#">Junkun Yuan</a>, 
          <a href="#">Ailing Zeng</a>, 
          <a href="#">Chengfei Cai</a>, 
          <a href="https://scholar.google.com.hk/citations?user=9akH-n8AAAAJ&hl=en">Heung-Yeung Shum</a>, 
          <a href="https://scholar.google.com/citations?user=AjxoEpIAAAAJ&hl=zh-CN">Wei Liu</a>, 
          <a href="https://cqf.io/">Qifeng Chen</a>
          <br>
          <em>SIGGRAPH Asia</em>, 2024
          <br>
          <a href="https://follow-your-emoji.github.io/">Project page</a> / 
          <a href="https://arxiv.org/abs/2406.01900">arXiv</a>
          <p></p>
          <p>
          </p>
        </td>
      </tr>

      <!-- Animate-a-story -->
      <tr >
        <td style="padding:20px;width:25%;vertical-align:middle">
          <video  width=100% height=100% muted autoplay loop>
            <source src="myassets/teddybear.mp4" type="video/mp4">
            Your browser does not support the video tag.
            </video>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://ailab-cvc.github.io/Animate-A-Story/">
            <span class="papertitle">Animate-A-Story: Storytelling with Retrieval-Augmented Video Generation</span>
          </a>
          <br>
          <strong>Yingqing He</strong>,
          <a href="https://menghanxia.github.io/" target="_blank">Menghan Xia</a>,
          <font style="color: #1772d0;">Haoxin Chen, </font> &nbsp;
          <a href="http://vinthony.github.io/" target="_blank">Xiaodong Cun</a>,
          <font style="color: #1772d0;">Yuan Gong, </font> &nbsp;
          <a href="https://doubiiu.github.io/" target="_blank">Jinbo Xing</a>,
          <a href="https://yzhang2016.github.io" target="_blank">Yong Zhang</a>,

          <a href="https://xinntao.github.io/" target="_blank">Xintao Wang</a>,
          <font style="color: #1772d0;">Chao Weng, </font> &nbsp;
          <a href="https://scholar.google.com/citations?hl=zh-CN&user=4oXBp9UAAAAJ" target="_blank">Ying Shan</a>,
          <a href="https://cqf.io/" target="_blank">Qifeng Chen</a>
          <br>
          <em>ECCV AI4VA Workshop</em>, 2024 &nbsp 
          <br>
          <a href="https://ailab-cvc.github.io/Animate-A-Story/">Project page</a> / 
          <a href="https://arxiv.org/abs/2307.06940">arXiv</a> / 
          <a href="https://github.com/AILab-CVC/Animate-A-Story">Github</a>
          <p></p>
          <p>
          A novel story-to-video pipeline with both structure and character controls, facilitating the generation of a vlog for a teddy bear.
          </p>
        </td>
      </tr>

      
      <!-- cheapscaling -->
      <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <img src='myassets/cheap.jpg' width="100%" height="60%">
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://guolanqing.github.io/Self-Cascade/">
            <span class="papertitle">Make a Cheap Scaling: A Self-Cascade Diffusion Model for Higher-Resolution Adaptation</span>
          </a>
          <br>
          <a href="https://scholar.google.com/citations?user=8rkIFHcAAAAJ&hl=zh-CN" >Lanqing Guo</a><sup>*</sup>,
          <strong>Yingqing He</strong><sup>*</sup>,
          <a href="https://scholar.google.com/citations?user=6UPJSvwAAAAJ&hl=zh-CN" target="_blank">Haoxin Chen</a>,
          <a href="https://menghanxia.github.io/" target="_blank">Menghan Xia</a>,
          <a href="http://vinthony.github.io/" target="_blank">Xiaodong Cun</a>,
          <a href="https://wyf0912.github.io/" target="_blank">Yufei Wang</a>,
          <font style="color: #1772d0;">Siyu Huang, </font> &nbsp;
          <a href="https://yzhang2016.github.io" target="_blank">Yong Zhang</a>,
          <a href="https://xinntao.github.io/" target="_blank">Xintao Wang</a>,
          <a href="https://cqf.io/" target="_blank">Qifeng Chen</a>,
          <a href="https://scholar.google.com/citations?hl=en&user=4oXBp9UAAAAJ&view_op=list_works&sortby=pubdate">Ying Shan</a>, 
          <a href="https://personal.ntu.edu.sg/bihan.wen/" target="_blank">Binhan Wen</a>
          <br>
          <em>ECCV</em>, 2024
          <br>
          <a href="https://guolanqing.github.io/Self-Cascade/">Project page</a> / 
          <a href="https://arxiv.org/abs/2402.10491">arXiv</a> / 
          <a href="https://github.com/GuoLanqing/Self-Cascade/">Github</a>
          <p></p>
          <p>
          </p>
        </td>
      </tr>

      <!-- seeing-and-hearing -->
      <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <img src='myassets/seeing.png' width="100%" height="60%">
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://yzxing87.github.io/Seeing-and-Hearing/">
            <span class="papertitle">Seeing and Hearing: Open-domain Visual-Audio Generation with Diffusion Latent Aligners</span>
          </a>
          <br>
          <a href="https://yzxing87.github.io/" >Yazhou Xing</a><sup>*</sup>,
          <strong>Yingqing He</strong><sup>*</sup>,
          <!-- <a href="#" target="_blank">Zeyue Tian</a>, -->
          <font style="color: #1772d0;">Zeyue Tian, </font> &nbsp;
          <a href="https://xinntao.github.io/" target="_blank">Xintao Wang</a>,
          <a href="https://cqf.io/" target="_blank">Qifeng Chen</a>
          <br>
          <em>CVPR</em>, 2024
          <br>
          <a href="https://yzxing87.github.io/Seeing-and-Hearing/">Project page</a> / 
          <a href="https://arxiv.org/abs/2402.17723">arXiv</a> / 
          <a href="https://github.com/yzxing87/Seeing-and-Hearing">Github</a>
          <p></p>
          <p>
          </p>
        </td>
      </tr>

      

      <tr bgcolor="#ffffd0">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <video  width=100% height=100% muted autoplay loop>
            <source src="myassets/scalecrafter.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://yingqinghe.github.io/scalecrafter/">
            <span class="papertitle">Scalecrafter: Tuning-free higher-resolution visual generation with diffusion models</span>
          </a>
          <br>
          <!-- <a href="https://bmild.github.io/">Ben Mildenhall</a>,
          <a href="https://phogzone.com/">Peter Hedman</a>,
          <a href="http://www.ricardomartinbrualla.com/">Ricardo Martin-Brualla</a>, <br>
          <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>, -->
          <strong>Yingqing He</strong><sup>*</sup>,
          <font style="color: #1772d0;">Shaoshu Yang, </font> &nbsp;
          <font style="color: #1772d0;">Haoxin Chen, </font> &nbsp;
          <a href="http://vinthony.github.io/" target="_blank">Xiaodong Cun</a>,
          <a href="https://menghanxia.github.io/" target="_blank">Menghan Xia</a>,
          <a href="https://yzhang2016.github.io" target="_blank">Yong Zhang</a>,
          <a href="https://xinntao.github.io/" target="_blank">Xintao Wang</a>,
          <font style="color: #1772d0;">Ran He, </font> &nbsp;
          <a href="https://cqf.io/" target="_blank">Qifeng Chen</a>,
          <a href="https://scholar.google.com/citations?hl=zh-CN&user=4oXBp9UAAAAJ" target="_blank">Ying Shan</a>
          <br>
          <em>ICLR</em>, 2024 &nbsp <font color="red"><strong>(Spotlight)</strong></font>
          <br>
          <a href="https://bmild.github.io/rawnerf/index.html">Project page</a> / 
          <a href="https://arxiv.org/abs/2310.07702">arXiv</a> / 
          <a href="https://github.com/YingqingHe/ScaleCrafter">Github</a>
          <p></p>
          <p>
            Generating 16x higher-resolution images and 4x higher-resolution videos without any extra data and training effort.
          </p>
        </td>
      </tr> 
      
      <!-- MagicStick -->
      <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <video  width=100% height=100% muted autoplay loop>
            <source src="myassets/magicstick.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://magic-stick-edit.github.io/">
            <span class="papertitle">MagicStick: Controllable Video Editing via Control Handle Transformations</span>
          </a>
          <br>
          <a href="https://mayuelala.github.io/" >Yue Ma</a>,
          <a href="http://vinthony.github.io/" target="_blank">Xiaodong Cun</a>,
          <strong>Yingqing He</strong>,
          <a href="https://chenyangqiqi.github.io/">Chenyang Qi</a>, 
          <a href="https://xinntao.github.io/" target="_blank">Xintao Wang</a>,
          <a href="https://scholar.google.com/citations?hl=en&user=4oXBp9UAAAAJ&view_op=list_works&sortby=pubdate">Ying Shan</a>, 
          <font style="color: #1772d0;">Xiu Li, </font> &nbsp;
          <a href="https://cqf.io/" target="_blank">Qifeng Chen</a>
          <br>
          <em>arXiv</em>, 2023
          <br>
          <a href="https://magic-stick-edit.github.io/">Project page</a> / 
          <a href="https://arxiv.org/abs/2312.03047">arXiv</a> / 
          <a href="https://github.com/mayuelala/MagicStick">Github</a>
          <p></p>
          <p>
          </p>
        </td>
      </tr>

      <!-- Freenoise -->
      <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <video  width=100% height=100% muted autoplay loop>
            <source src="myassets/freenoise.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="http://haonanqiu.com/projects/FreeNoise.html">
            <span class="papertitle">Freenoise: Tuning-free longer video diffusion via noise rescheduling</span>
          </a>
          <br>
          <a href="http://haonanqiu.com/">Haonan Xiu</a>, 
          <a href="https://menghanxia.github.io/" target="_blank">Menghan Xia</a>,
          <a href="https://yzhang2016.github.io" target="_blank">Yong Zhang</a>,
          <strong>Yingqing He</strong>,
          <a href="https://xinntao.github.io/">Xintao Wang</a>,
          <a href="https://scholar.google.com/citations?hl=en&user=4oXBp9UAAAAJ&view_op=list_works&sortby=pubdate">Ying Shan</a>, 
          <a href="https://liuziwei7.github.io/">Ziwei Liu</a>
          <br>
          <em>ICLR</em>, 2024
          <br>
          <a href="http://haonanqiu.com/projects/FreeNoise.html">Project page</a> / 
          <a href="https://arxiv.org/abs/2310.15169">arXiv</a> /
          <a href="https://github.com/AILab-CVC/FreeNoise">Github</a>
          <p></p>
          <p>
          </p>
        </td>
      </tr>


      <!-- Follow-your-pose -->
      <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <video  width=100% height=100% muted autoplay loop>
            <source src="myassets/fyp/girl_yellow.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://follow-your-pose.github.io/">
            <span class="papertitle">Follow your pose: Pose-guided text-to-video generation using pose-free videos</span>
          </a>
          <br>
          <a href="https://mayuelala.github.io/" >Yue Ma</a><sup>*</sup>,
          <strong>Yingqing He</strong><sup>*</sup>,
          <a href="https://vinthony.github.io/academic/">Xiaodong Cun</a>, 
          <a href="https://xinntao.github.io/">Xintao Wang</a>, 
          <font style="color: #1772d0;">Siran Chen, </font> &nbsp;
          <a href="https://scholar.google.com/citations?hl=en&user=4oXBp9UAAAAJ&view_op=list_works&sortby=pubdate">Ying Shan</a>, 
          <font style="color: #1772d0;">Xiu Li, </font> &nbsp;
          <a href="https://cqf.io/">Qifeng Chen</a>
          <br>
          <em>AAAI</em>, 2024
          <br>
          <a href="https://follow-your-pose.github.io/">Project page</a> / 
          <a href="https://arxiv.org/abs/2304.01186">arXiv</a> / 
          <a href="https://github.com/mayuelala/FollowYourPose">Github</a>
          <p></p>
          <p>
          </p>
        </td>
      </tr>

      <!-- Make-Your-Video -->
      <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <video  width=100% height=100% muted autoplay loop>
            <source src="myassets/myv.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://doubiiu.github.io/projects/Make-Your-Video/">
            <span class="papertitle">Make-Your-Video: Customized Video Generation Using Textual and Structural Guidance</span>
          </a>
          <br>
          <a href="https://doubiiu.github.io/" >Jinbo Xing</a>, 
          <a href="https://menghanxia.github.io/">Menghan Xia</a>, 
          <font style="color: #1772d0;">Yuxin Liu, </font> &nbsp;
          <a href="https://julianjuaner.github.io/">Yuechen Zhang</a>, 
          <a href="https://yzhang2016.github.io/">Yong Zhang</a>, 
          <strong>Yingqing He</strong>, 
          <a href="https://github.com/hyliu">Hanyuan Liu</a>, 
          <font style="color: #1772d0;">Haoxin Chen, </font> &nbsp;
          <a href="https://vinthony.github.io/academic/">Xiaodong Cun</a>, 
          <a href="https://xinntao.github.io/">Xintao Wang</a>, 
          <a href="https://scholar.google.com/citations?hl=en&user=4oXBp9UAAAAJ&view_op=list_works&sortby=pubdate">Ying Shan</a>, 
          <a href="https://www.cse.cuhk.edu.hk/~ttwong/myself.html">Tien-Tsin Wong</a>
          <br>
          <!-- <em>arXiv</em>, 2023 -->
          <em>TVCG</em>, 2024
          <br>
          <a href="https://doubiiu.github.io/projects/Make-Your-Video/">Project page</a> / 
          <a href="https://arxiv.org/abs/2306.00943">arXiv</a>
          <p></p>
          <p>Given text description and video structure (depth), our approach can generate temporally coherent and high-fidelity videos. Its applications include dynamic 3d-scene-to-video creation, real-life scene to video, and video rerendering.
          </p>
        </td>
      </tr>

      <!-- TaleCrafter -->
      <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <video  width=100% height=100% muted autoplay loop>
            <source src="myassets/talecrafter.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://ailab-cvc.github.io/TaleCrafter/">
            <span class="papertitle">TaleCrafter: Interactive Story Visualization with Multiple Characters</span>
          </a>
          <br>
          <font style="color: #1772d0;">Yuan Gong, </font> &nbsp;
          <font style="color: #1772d0;">Youxi Pang, </font> &nbsp;
          <a href="https://vinthony.github.io/academic/">Xiaodong Cun</a>, 
          <a href="https://menghanxia.github.io/" target="_blank">Menghan Xia</a>,
          <strong>Yingqing He</strong>,
          <font style="color: #1772d0;">Haoxin Chen, </font> &nbsp;
          <font style="color: #1772d0;">Longyue Wang, </font> &nbsp;
          <a href="https://yzhang2016.github.io" target="_blank">Yong Zhang</a>,
          <a href="https://xinntao.github.io/">Xintao Wang</a>,
          <a href="https://scholar.google.com/citations?hl=en&user=4oXBp9UAAAAJ&view_op=list_works&sortby=pubdate">Ying Shan</a>, 
          <a href="https://sites.google.com/view/iigroup-thu/home">Yujiu Yang</a>
          <br>
          <em>SIGGRAPH Asia</em>, 2023
          <br>
          <a href="https://ailab-cvc.github.io/TaleCrafter/">Project page</a> / 
          <a href="https://arxiv.org/abs/2305.18247">arXiv</a> / 
          <a href="https://github.com/AILab-CVC/TaleCrafter">Github</a>
          <p></p>
          <p>
          </p>
        </td>
      </tr>
      
      <!-- Videocrafter1 -->
      <tr bgcolor="#ffffd0">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <img src='myassets/videocrafter/girl.gif' width="100%" height=75% >
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://ailab-cvc.github.io/videocrafter/">
            <span class="papertitle">Videocrafter1: Open diffusion models for high-quality video generation</span>
          </a>
          <br>
          <a href="#">Haoxin Chen</a><sup>*</sup>,
          <a href="https://menghanxia.github.io/">Menghan Xia</a><sup>*</sup>,
          <strong>Yingqing He</strong><sup>*</sup>,
          <a href="https://yzhang2016.github.io/">Yong Zhang</a>,
          <a href="https://vinthony.github.io/academic/">Xiaodong Cun</a>,
          <font style="color: #1772d0;">Shaoshu Yang, </font> &nbsp;
          <a href="https://doubiiu.github.io/" >Jinbo Xing</a>, 
          <font style="color: #1772d0;">Yaofang Liu, </font> &nbsp;
          <a href="https://cqf.io/">Qifeng Chen</a>,
          <a href="https://xinntao.github.io/">Xintao Wang</a>,
          <font style="color: #1772d0;">Chao Weng, </font> &nbsp;
          <a href="https://scholar.google.com/citations?hl=en&user=4oXBp9UAAAAJ&view_op=list_works&sortby=pubdate">Ying Shan</a>
          <br>
          <em>arXiv</em>, 2023
          <br>
          <a href="https://ailab-cvc.github.io/videocrafter/">Project page</a> /
          <a href="https://arxiv.org/abs/2310.19512">arXiv</a> /
          <a href="https://github.com/AILab-CVC/VideoCrafter">Github</a> 
          <p>
            An open-sourced foundational text-to-video and image-to-video diffusion model for high-quality video generation.
          </p>
        </td>
      </tr>

      <!-- LVDM -->
      <tr bgcolor="#ffffd0">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <video  width=100% height=100% muted autoplay loop>
            <source src="myassets/lvdm.mp4" type="video/mp4">
            Your browser does not support the video tag.
            </video>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://yingqinghe.github.io/LVDM/">
            <span class="papertitle">Latent Video Diffusion Models for High-Fidelity Long Video Generation</span>
          </a>
          <br>
          <strong>Yingqing He</strong>,
          <a href="https://tianyu-yang.com/">Tianyu Yang</a>, 
          <a href="https://yzhang2016.github.io" target="_blank">Yong Zhang</a>,
          <a href="https://scholar.google.com/citations?hl=en&user=4oXBp9UAAAAJ&view_op=list_works&sortby=pubdate">Ying Shan</a>, 
          <a href="https://cqf.io/" target="_blank">Qifeng Chen</a>
          <br>
          <em>arXiv</em>, 2022
          <br>
          <a href="https://yingqinghe.github.io/LVDM/">Project page</a> / 
          <a href="https://arxiv.org/abs/2211.13221">arXiv</a> / 
          <a href="https://github.com/YingqingHe/LVDM">Github</a>
          <p></p>
          <p>
          </p>
        </td>
      </tr>


      
      

      <!-- interclassgan -->
      <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <img src='myassets/interclassgan.jpeg' width="100%">
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://yingqinghe.github.io/interclassgan/">
            <span class="papertitle">Interpreting class conditional GANs with channel awareness</span>
          </a>
          <br>
          <strong>Yingqing He</strong>,
          <font style="color: #1772d0;">Zhiyi Zhang, </font> &nbsp;
          <font style="color: #1772d0;">Jiapeng Zhu, </font> &nbsp;
          <a href="https://shenyujun.github.io/" target="_blank">Yujun Shen</a>,
          <a href="https://cqf.io/" target="_blank">Qifeng Chen</a>
          <br>
          <em>arXiv</em>, 2022
          <br>
          <a href="https://yingqinghe.github.io/interclassgan/">Project page</a> /
          <a href="https://arxiv.org/abs/2203.11173">arXiv</a> /
          <a href="https://github.com/yingqinghe/interclassgan">Github</a>
          <p></p>
          <p>
          </p>
        </td>
      </tr>


      <!-- Shadow -->
      <tr bgcolor="#ffffd0">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <img src='myassets/shadow.jpg' width="100%">
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://github.com/YingqingHe/Shadow-Removal-via-Generative-Priors">
            <span class="papertitle">Unsupervised portrait shadow removal via generative priors</span>
          </a>
          <br>
          <strong>Yingqing He</strong><sup>*</sup>,
          <!-- <a href="" target="_blank">Yazhou Xing</a><sup>*</sup>, -->
          <font style="color: #1772d0;">Yazhou Xing, </font> &nbsp;
          <font style="color: #1772d0;">Tianjia Zhang, </font> &nbsp;
          <a href="https://cqf.io/" target="_blank">Qifeng Chen</a>
          <br>
          <!-- <em>arXiv</em>, 2023 -->
          <em>ACM MM</em>, 2021 &nbsp <font color="red"><strong>(Oral)</strong></font>
          <br>
          <a href="https://arxiv.org/abs/2108.03466">arXiv</a> / 
          <a href="https://github.com/YingqingHe/Shadow-Removal-via-Generative-Priors">Github</a>
          <p></p>
          <p>we propose an unsupervised method for portrait shadow removal, leveraging the facial priors from <em>StyleGAN2</em>.
            Our approach also supports facial tattoo and watermark removal.
          </p>
        </td>
      </tr>
      
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr>
      <td style="padding:20px;width:100%;vertical-align:middle">
        <h2>Academic Services</h2>
        <p>
          Conference Reviewer for CVPR, SIGGRAPH Asia.<br>
          Journal Reviewer for TPAMI, IJCV, ACM Computing Surveys.
        </p>
      </td>
    </tr>
    </tbody></table>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

    <!-- </tbody></table>
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Miscellanea</h2>
              </td>
            </tr>
          </tbody></table>
          <table width="100%" align="center" border="0" cellpadding="20"><tbody>
            
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td>
              <td width="75%" valign="center">
                <a href="https://cvpr2023.thecvf.com/Conferences/2023/Organizers">Demo Chair, CVPR 2023</a>
          <br>
                <a href="https://cvpr2022.thecvf.com/area-chairs">Area Chair, CVPR 2022</a>
                <br>
                <a href="http://cvpr2021.thecvf.com/area-chairs">Area Chair & Longuet-Higgins Award Committee Member, CVPR 2021</a>
                <br>
                <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>
                <br>
                <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>
              </td>
            </tr>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/cs188.jpg" alt="cs188">
              </td>
              <td width="75%" valign="center">
                <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Student Instructor, CS188 Spring 2011</a>
                <br>
                <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student Instructor, CS188 Fall 2010</a>
                <br>
                <a href="http://aima.cs.berkeley.edu/">Figures, "Artificial Intelligence: A Modern Approach", 3rd Edition</a>
              </td>
            </tr>
            

            <tr>
              <td align="center" style="padding:20px;width:25%;vertical-align:middle">
                <h2>Basically <br> Blog Posts</h2>
              </td>
              <td width="75%" valign="middle">
                <a href="https://arxiv.org/abs/2112.11687">Squareplus: A Softplus-Like Algebraic Rectifier</a>
                <br>
                <a href="https://arxiv.org/abs/2010.09714">A Convenient Generalization of Schlick's Bias and Gain Functions</a>
                <br>
                <a href="https://arxiv.org/abs/1704.07483">Continuously Differentiable Exponential Linear Units</a>
                <br>
                <a href="https://jonbarron.info/data/cvpr2023_llm_workshop_annotated.pdf">Scholars & Big Models: How Can Academics Adapt?</a>
              </td>
            </tr>
          </tbody></table> -->


          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  <!-- Feel free to steal this website's <a href="https://github.com/jonbarron/jonbarron_website">source code</a>. <strong>Do not</strong> scrape the HTML from this page itself, as it includes analytics tags that you do not want on your own website &mdash; use the github code instead. Also, consider using <a href="https://leonidk.com/">Leonid Keselman</a>'s <a href="https://github.com/leonidk/new_website">Jekyll fork</a> of this page. -->
                  Webpage templete is borrowed from <a href="https://github.com/jonbarron/jonbarron_website">this</a>
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
